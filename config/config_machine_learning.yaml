# Machine Learning Configuration File
# This configuration file defines all parameters for data loading, preprocessing, feature selection, model training, and evaluation.

#%%================================================================================
# Data Input Configuration
# Multiple input files can be specified for model ensemble or feature combination
input:
  - path: H:\results\ml_results\autogluon_clinical\autogluon_clinical_pred_full.csv # Path to the input data file (CSV format)
    name: clinical_  # Prefix for feature names from this file. Default is empty. Used to prevent feature name conflicts when using multiple datasets
    subject_id_col: subjID  # Column name containing subject identifiers (must be unique for each subject)
    label_col: true_label  # Column name containing target labels (0/1 for binary classification)
    features: [prob]   # Optional list of specific features to use from this file. If not provided, all available features will be used (except subject_id_col and label_col)
  
  # # Example of additional input file configuration (commented out)
  - path: H:\results\ml_results\autogluon_habitat\autogluon_habitat_pred_full.csv
    name: habitat_  # Prefix clinical_ will be added to all features from this file
    subject_id_col: subjID  # Column name for subject ID in this file
    label_col: true_label  # Column name for the target variable in this file
    features: [prob]  # Only use the LogisticRegression_prob column as a feature

  # # # # Example of additional input file configuration (commented out)
  # - path: H:\results\ml_results\autogluon_radiomics\autogluon_radiomics_pred_full.csv
  #   name: radiomics_  # Prefix clinical_ will be added to all features from this file
  #   subject_id_col: subjID  # Column name for subject ID in this file
  #   label_col: true_label  # Column name for the target variable in this file
  #   features: [prob]  # Only use the LogisticRegression_prob column as a feature

#%%================================================================================
# Output Directory Configuration
output: H:\results\ml_results\merged_clinicalPlusHabitat  # Directory where all results will be saved (models, plots, statistics)

#%%================================================================================
# Data Splitting Configuration
# Options: random (completely random split), stratified (preserves class distribution), custom (user-defined splits)
split_method: custom  # Method used to split data into training and testing sets
# The following parameters are used when split_method is random or stratified (currently commented out)
# test_size: 0.3  # Proportion of data to be used for testing (between 0.0 and 1.0)
# random_state: 42  # Seed for random number generator to ensure reproducible splits
# The following parameters are used when split_method is custom
train_ids_file: H:\results\ml_results\train_ids.txt  # File containing IDs for training set (one ID per line)
test_ids_file: H:\results\ml_results\test_ids.txt  # File containing IDs for testing set (one ID per line)

#%%================================================================================
# Normalization Configuration
# Several options are available:
normalization:
  method: z_score  # Standardization method (zero mean, unit variance)
  # method: min_max  # Scale features to a specific range [0,1] by default
  # params:
  #   feature_range: [0, 1]  # Range to scale features to

  # method: robust  # Scale features using statistics robust to outliers
  # params:
  #   quantile_range: [25.0, 75.0]  # Percentile range to compute the robust scaling
  #   with_centering: true  # Whether to center the data before scaling
  #   with_scaling: true  # Whether to scale the data to interquartile range

  # method: max_abs  # Scale each feature by its maximum absolute value
  
  # method: normalizer  # Scale samples to have unit norm
  # params:
  #   norm: l2  # Norm to use (l1, l2, or max)

  # method: quantile  # Transform features to follow uniform or normal distribution
  # params:
  #   n_quantiles: 1000  # Number of quantiles to use
  #   output_distribution: uniform  # Output distribution (uniform or normal)

  # method: power  # Apply power transform to make data more Gaussian-like
  # params:
  #   method: yeo-johnson  # Transformation method (yeo-johnson or box-cox)
  #   standardize: true  # Whether to standardize the data to zero mean and unit variance

#%%================================================================================
# Feature Selection Configuration
# Multiple feature selection methods can be applied sequentially
feature_selection_methods:
  # # ICC (Intraclass Correlation Coefficient) method
  # - method: icc  # Selects features based on their reproducibility
  #   params:
  #     icc_results: H:\results\icc_results.json  # Path to pre-computed ICC results
  #     keys: [raw_image_radiomics_vs_raw_image_radiomics]  # Key(s) in the ICC results file to use
  #     threshold: 0.8  # Minimum ICC value required to retain a feature (0.0-1.0)
  #     before_z_score: false  # Whether to run this method before Z-score normalization (default: false)
  
  # 方差选择器 - 移除低方差特征
  # - method: variance
  #   params:
  #     before_z_score: true  # 是否在Z-score标准化之前执行（推荐为true，因为标准化后所有特征方差均为1）
  #     threshold: 0.2  # 方差阈值（特征方差必须大于此值才会被保留）
  #     plot_variances: true  # 是否生成方差可视化图表

  # # 统计检验选择器 - 自动选择t检验或Mann-Whitney U检验
  # - method: statistical_test
  #   params:
  #     p_threshold: 0.05  # P值阈值（特征P值必须小于此值才会被保留）
  #     # n_features_to_select: 20  # 可选：要选择的特征数量（如果指定，则覆盖p_threshold）
  #     normality_test_threshold: 0.05  # 正态性检验的阈值
  #     plot_importance: true  # 是否生成特征重要性图表
  #     before_z_score: false  # 是否在Z-score标准化之前执行（默认为false）
      # force_test: "ttest"  # 可选：强制使用特定检验方法（"ttest"或"mannwhitney"）

  # # VIF (Variance Inflation Factor) method - removes features with high multicollinearity
  # - method: vif  # Removes features with high multicollinearity
  #   params:
  #     max_vif: 10  # Maximum allowed VIF value; features with higher values will be removed
  #     visualize: false  # Whether to generate visualization of VIF values
  #     before_z_score: false  # Whether to run this method before Z-score normalization (default: false)

  # # Correlation method - removes highly correlated features
  # - method: correlation
  #   params:
  #     threshold: 0.80  # Correlation threshold (features with correlation above this value will be removed)
  #     method: spearman  # Correlation method: pearson, spearman, or kendall
  #     visualize: false  # Whether to generate correlation heatmap
  #     before_z_score: false  # Whether to run this method before Z-score normalization (default: false)

  # # ANOVA method - selects features based on ANOVA F-value
  # - method: anova
  #   params:
  #     p_threshold: 0.05  # P-value threshold for feature selection (features with p < threshold are retained)
  #     # n_features_to_select: 20  # Optional: Number of top features to select (if specified, overrides p_threshold)
  #     plot_importance: true  # Whether to plot feature importance
  #     before_z_score: false  # Whether to run this method before Z-score normalization (default: false)

  # # Chi2 method - selects features based on chi-square test (only for non-negative features)
  # - method: chi2
  #   params:
  #     p_threshold: 0.05  # P-value threshold for feature selection (features with p < threshold are retained)
  #     # n_features_to_select: 20  # Optional: Number of top features to select (if specified, overrides p_threshold)
  #     plot_importance: true  # Whether to plot feature importance
  #     before_z_score: false  # Whether to run this method before Z-score normalization (default: false)

  # - method: rfecv
  #   params:
  #     estimator: LogisticRegression
  #     cv: 10
  #     step: 1
  #     min_features_to_select: 1
  #     before_z_score: false  # Whether to run this method before Z-score normalization (default: false)
  
  # mRMR (Minimum Redundancy Maximum Relevance) method
  # - method: mrmr  # Selects features with high relevance to target and low redundancy among themselves
  #   params:
  #     n_features: 5  # Number of features to select
  #     visualize: false  # Whether to generate visualization of selected features
  #     before_z_score: false  # Whether to run this method before Z-score normalization (default: false)

  # LASSO (L1 regularization) method - selects features using L1 regularization
  # - method: lasso  # Selects features using L1 regularization
  #   params:
  #     cv: 10  # Number of cross-validation folds for selecting optimal alpha
  #     n_alphas: 100  # Number of alpha values to try
  #     alphas: [0.01, 0.1, 1.0, 10, 100]  # Alpha values to try
  #     random_state: 42  # Random seed for reproducibility
  #     visualize: true  # Whether to generate visualization of feature coefficients
  #     before_z_score: false  # Whether to run this method before Z-score normalization (default: false)
  
  # # Univariate Logistic Regression method
  # - method: univariate_logistic  # Selects features based on individual logistic regression p-values
  #   params:
  #     threshold: 0.1  # Maximum p-value threshold for feature selection (features with p < threshold are retained)
  #     before_z_score: false  # Whether to run this method before Z-score normalization (default: false)

  # # Stepwise Feature Selection method
  # - method: stepwise  # Performs step-by-step feature selection using AIC/BIC criteria
  #   params:
  #     criterion: aic  # Criterion for selection: aic, bic
  #     direction: forward  # Direction of stepwise selection: forward, backward, or both
  #     before_z_score: false  # Whether to run this method before Z-score normalization (default: false)

#%%================================================================================
# Model Configuration
# Multiple models can be defined and will all be trained and evaluated
models:
  # Logistic Regression model configuration
  LogisticRegression:  # Model type: Standard logistic regression classifier
    params:
      random_state: 42  # Random seed for reproducibility
      max_iter: 1000  # Maximum number of iterations for convergence
      C: 1.0  # Inverse of regularization strength (smaller values = stronger regularization)
      penalty: "l2"  # Regularization type (l1=Lasso, l2=Ridge)
      solver: "lbfgs"  # Algorithm to use in the optimization problem
  
  # # AutoGluonTabular model configuration
  # AutoGluonTabular:  # Model type: AutoGluonTabular classifier
  #   params:
  #     time_limit: 60
  #     random_state: 42  # Random seed for reproducibility
  #     presets: "high_quality"  # Preset for AutoGluonTabular
  #     verbosity: 4  # Verbosity level for AutoGluonTabular
  #     eval_metric: "roc_auc"  # Evaluation metric for AutoGluonTabular
  # # Support Vector Machine configuration
  # SVM:  # Model type: Support Vector Machine classifier
  #   params:
  #     random_state: 42  # Random seed for reproducibility

  # # XGBoost configuration
  # XGBoost:  # Model type: Gradient Boosting classifier
  #   params:
  #     random_state: 42  # Random seed for reproducibility
  #     n_estimators: 100  # Number of boosting stages/trees to build
  #     max_depth: 3  # Maximum tree depth
  #     learning_rate: 0.1  # Boosting learning rate
  #     subsample: 0.8  # Fraction of samples used for fitting trees
  #     colsample_bytree: 0.8  # Fraction of features used per tree
  #     objective: "binary:logistic"  # Objective function for optimization
  #     eval_metric: "logloss"  # Evaluation metric during training

#%%================================================================================  
# Visualization and Saving Configuration
is_visualize: true  # Whether to generate performance visualization plots (ROC, calibration curves, etc.)
is_save_model: true  # Whether to save trained models to disk for future use

