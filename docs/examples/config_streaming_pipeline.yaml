# Habitat Analysis Configuration - Streaming Pipeline for Memory Efficiency
# Use this configuration when processing large datasets with limited memory

data_dir: "path/to/your/data"
out_dir: "path/to/output"
run_mode: "train"

# ============================================================================
# STREAMING PIPELINE CONFIGURATION (默认已启用)
# ============================================================================
# 流式处理已默认启用，无需额外配置
# 如果要禁用流式处理（使用标准pipeline，所有subjects同时在内存中）：
# use_streaming_pipeline: false

# Batch size 控制内存 vs 速度的权衡：
# - streaming_batch_size: 1  → 最小内存 (~160MB/subject)，最慢
# - streaming_batch_size: 10 → 平衡配置（推荐）
# - streaming_batch_size: 20 → 更快但占用更多内存
# - streaming_batch_size: 0  → 禁用批处理（一次处理所有subjects）
streaming_batch_size: 10

# ============================================================================
# 并行处理设置
# ============================================================================
# 并行进程数（在每个batch内部并行处理）
# 流式处理 + 并行的组合效果：
# - 内存占用 ≈ streaming_batch_size × (160MB base + parallel overhead)
# - 示例：batch_size=10, processes=4 → 约 2-3GB 峰值内存
# - 如果内存充足，可以增大 batch_size 和 processes 以加速
processes: 4

# Other settings
plot_curves: true
save_images: true
save_results_csv: true
random_state: 42
verbose: true
debug: false

# ============================================================================
# FEATURE CONSTRUCTION
# ============================================================================
FeatureConstruction:
  voxel_level:
    method: "pyradiomics_extractor()"
    params:
      normalize: true
      
  supervoxel_level:
    method: "mean_voxel_features()"  # Simple aggregation
    supervoxel_file_keyword: "*_supervoxel.nrrd"
    
  preprocessing_for_subject_level:
    methods:
      - method: "zscore"
        global_normalize: false
        
  preprocessing_for_group_level:
    methods:
      - method: "robust"
        global_normalize: true

# ============================================================================
# HABITAT SEGMENTATION
# ============================================================================
HabitatsSegmention:
  clustering_mode: "two_step"  # Required for streaming
  
  supervoxel:
    algorithm: "kmeans"
    n_clusters: 3
    random_state: 42
    
  habitat:
    algorithm: "kmeans"
    n_clusters: 4
    random_state: 42

# ============================================================================
# MEMORY COMPARISON
# ============================================================================
# Standard Pipeline (use_streaming_pipeline: false):
#   - 100 subjects → ~16GB peak memory
#   - Fastest processing
#   
# Streaming Pipeline (use_streaming_pipeline: true, batch_size: 10):
#   - 100 subjects → ~1.6GB peak memory (10x reduction)
#   - Slightly slower but much more memory efficient
#
# Extreme Memory Saving (use_streaming_pipeline: true, batch_size: 1):
#   - 100 subjects → ~160MB peak memory (100x reduction!)
#   - Slowest but works on any machine
