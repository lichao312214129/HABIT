Metrics Module Optimization
===========================

ä¼˜åŒ–æ¦‚è¿°
--------

æœ¬æ¬¡ä¼˜åŒ–å¯¹ ``habit/core/machine_learning/evaluation/metrics.py`` æ¨¡å—è¿›è¡Œäº†å…¨é¢æ”¹è¿›ï¼Œåœ¨ä¿æŒå‘åå…¼å®¹çš„å‰æä¸‹ï¼Œå®ç°äº†æ€§èƒ½æå‡å’ŒåŠŸèƒ½å¢å¼ºã€‚

ä¸»è¦ä¼˜åŒ–
--------

1. æ€§èƒ½ä¼˜åŒ–ï¼šæ··æ·†çŸ©é˜µç¼“å­˜ ğŸš€
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

**é—®é¢˜**ï¼šä¹‹å‰æ¯ä¸ªæŒ‡æ ‡å‡½æ•°éƒ½ç‹¬ç«‹è®¡ç®—æ··æ·†çŸ©é˜µï¼Œå¯¼è‡´é‡å¤è®¡ç®—8æ¬¡ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼šå¼•å…¥ ``MetricsCache`` ç±»

.. code-block:: python

    class MetricsCache:
        """Cache confusion matrix to avoid repeated calculations."""
        @property
        def confusion_matrix(self):
            if self._cm is None:
                self._cm = metrics.confusion_matrix(self.y_true, self.y_pred)
            return self._cm

**æ€§èƒ½æå‡**ï¼šçº¦ **8å€** é€Ÿåº¦æå‡ï¼ˆä»8æ¬¡æ··æ·†çŸ©é˜µè®¡ç®—é™è‡³1æ¬¡ï¼‰

**ä½¿ç”¨æ–¹æ³•**ï¼š

.. code-block:: python

    # Enable cache (default)
    metrics = calculate_metrics(y_true, y_pred, y_prob, use_cache=True)

    # Disable cache
    metrics = calculate_metrics(y_true, y_pred, y_prob, use_cache=False)

2. æ‰©å±•Target Metricsæ”¯æŒ ğŸ’¡
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

**æ–°å¢æ”¯æŒçš„æŒ‡æ ‡**ï¼š

* âœ… Sensitivityï¼ˆå·²æ”¯æŒï¼‰
* âœ… Specificityï¼ˆå·²æ”¯æŒï¼‰
* âœ… **PPV (Precision)** - æ–°å¢
* âœ… **NPV** - æ–°å¢
* âœ… **F1-score** - æ–°å¢
* âœ… **Accuracy** - æ–°å¢

**ä½¿ç”¨ç¤ºä¾‹**ï¼š

.. code-block:: python

    targets = {
        'sensitivity': 0.91,
        'specificity': 0.91,
        'ppv': 0.85,           # New
        'npv': 0.90,           # New
        'f1_score': 0.88       # New
    }

    result = calculate_metrics_at_target(y_true, y_pred_proba, targets)

.. note::
   PPV/NPV/F1ç­‰æŒ‡æ ‡éœ€è¦éå†æ‰€æœ‰é˜ˆå€¼è®¡ç®—ï¼Œæ€§èƒ½å¼€é”€è¾ƒå¤§ï¼Œä½†å¿…è¦ã€‚

3. Fallbackæœºåˆ¶ï¼šæœ€æ¥è¿‘é˜ˆå€¼ ğŸ¯
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

**é—®é¢˜**ï¼šå½“æ²¡æœ‰é˜ˆå€¼èƒ½åŒæ—¶æ»¡è¶³æ‰€æœ‰ç›®æ ‡æ—¶ï¼ˆå¦‚ç›®æ ‡è¿‡é«˜ï¼‰ï¼Œä¹‹å‰ä¼šç›´æ¥è¿”å›ç©ºç»“æœã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼šè‡ªåŠ¨å¯»æ‰¾"æœ€æ¥è¿‘"çš„é˜ˆå€¼

.. code-block:: python

    result = calculate_metrics_at_target(
        y_true, y_pred_proba,
        {'sensitivity': 0.99, 'specificity': 0.99},  # Impossible targets
        fallback_to_closest=True,
        distance_metric='euclidean'  # 'euclidean', 'manhattan', or 'max'
    )

    # Return structure
    {
        'closest_threshold': {
            'threshold': 0.5234,
            'metrics': {...},
            'distance_to_target': 0.0523,
            'satisfied_targets': ['sensitivity'],
            'unsatisfied_targets': ['specificity'],
            'warning': 'No threshold satisfies all targets. This is the closest match.'
        }
    }

**è·ç¦»åº¦é‡**ï¼š

* ``euclidean``: âˆšÎ£(actual - target)Â²ï¼ˆé»˜è®¤ï¼‰
* ``manhattan``: Î£|actual - target|
* ``max``: max(|actual - target|)

.. warning::
   **ä¸¥æ ¼é¿å…æ•°æ®æ³„éœ²**ï¼š
   
   * è®­ç»ƒé›†ï¼šæ‰¾åˆ°æœ€æ¥è¿‘é˜ˆå€¼
   * æµ‹è¯•é›†ï¼šåº”ç”¨è®­ç»ƒé›†çš„é˜ˆå€¼ï¼ˆä¸é‡æ–°æœç´¢ï¼‰

4. æ™ºèƒ½é˜ˆå€¼é€‰æ‹©ç­–ç•¥ ğŸ§ 
~~~~~~~~~~~~~~~~~~~~~~~~~~~

**é—®é¢˜**ï¼šå½“å¤šä¸ªé˜ˆå€¼éƒ½æ»¡è¶³æ¡ä»¶æ—¶ï¼Œå¦‚ä½•é€‰æ‹©æœ€ä¼˜ï¼Ÿ

**è§£å†³æ–¹æ¡ˆ**ï¼šä¸‰ç§ç­–ç•¥

ç­–ç•¥1ï¼šFirstï¼ˆå¿«é€Ÿï¼‰
^^^^^^^^^^^^^^^^^^^^

.. code-block:: python

    result = calculate_metrics_at_target(..., threshold_selection='first')
    # Return first threshold that meets criteria

ç­–ç•¥2ï¼šYoudenï¼ˆç»å…¸ï¼‰
^^^^^^^^^^^^^^^^^^^^^

.. code-block:: python

    result = calculate_metrics_at_target(..., threshold_selection='youden')
    # Return threshold with maximum Youden index
    # Youden = Sensitivity + Specificity - 1

ç­–ç•¥3ï¼šPareto+Youdenï¼ˆæ¨èï¼‰â­
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. code-block:: python

    result = calculate_metrics_at_target(..., threshold_selection='pareto+youden')
    # 1. Find all Pareto-optimal thresholds (not dominated by others)
    # 2. Select the one with maximum Youden index among Pareto-optimal

**è¿”å›ç»“æ„**ï¼š

.. code-block:: python

    {
        'best_threshold': {
            'threshold': 0.5222,
            'metrics': {...},
            'strategy': 'pareto+youden',
            'youden_index': 0.8792,
            'pareto_optimal_count': 3  # Number of Pareto-optimal thresholds
        }
    }

5. ç±»åˆ«ç­›é€‰åŠŸèƒ½ ğŸ“‹
~~~~~~~~~~~~~~~~~~~~~

**åŠŸèƒ½**ï¼šæŒ‰ç±»åˆ«ç­›é€‰è¦è®¡ç®—çš„æŒ‡æ ‡

.. code-block:: python

    # Calculate only basic metrics (fast)
    basic_metrics = calculate_metrics(
        y_true, y_pred, y_prob,
        categories=['basic']
    )
    # Returns: accuracy, sensitivity, specificity, ppv, npv, f1_score, auc

    # Calculate only statistical metrics
    stat_metrics = calculate_metrics(
        y_true, y_pred, y_prob,
        categories=['statistical']
    )
    # Returns: hosmer_lemeshow_p_value, spiegelhalter_z_p_value

    # Calculate multiple categories
    metrics = calculate_metrics(
        y_true, y_pred, y_prob,
        categories=['basic', 'statistical']
    )

    # Calculate all metrics (default)
    all_metrics = calculate_metrics(y_true, y_pred, y_prob)

6. å¤šåˆ†ç±»æ”¯æŒå‡†å¤‡ ğŸ”®
~~~~~~~~~~~~~~~~~~~~~~~

**å½“å‰çŠ¶æ€**ï¼š

* âœ… AUCï¼šå·²æ”¯æŒå¤šåˆ†ç±»ï¼ˆOne-vs-Restï¼‰
* âœ… åŸºç¡€æŒ‡æ ‡ï¼šæ–°å¢å¤šåˆ†ç±»æ”¯æŒï¼ˆmacro averageï¼‰

**å¤šåˆ†ç±»ç¤ºä¾‹**ï¼š

.. code-block:: python

    # Binary classification (current behavior)
    cm = [[TN, FP],
          [FN, TP]]
    sensitivity = TP / (TP + FN)

    # Multi-class classification (new support)
    cm = [[c00, c01, c02],
          [c10, c11, c12],
          [c20, c21, c22]]
    # Per-class recall, then macro average

å‘åå…¼å®¹æ€§ âœ…
--------------

æ‰€æœ‰ç°æœ‰ä»£ç  **æ— éœ€ä¿®æ”¹**ï¼Œé»˜è®¤è¡Œä¸ºä¿æŒä¸å˜ï¼š

.. code-block:: python

    # Old code still works
    metrics = calculate_metrics(y_true, y_pred, y_prob)
    result = calculate_metrics_at_target(y_true, y_prob, {'sensitivity': 0.9})

    # New features enabled via optional parameters
    metrics = calculate_metrics(y_true, y_pred, y_prob, use_cache=True, categories=['basic'])
    result = calculate_metrics_at_target(
        y_true, y_prob, targets,
        threshold_selection='pareto+youden',
        fallback_to_closest=True
    )

ä½¿ç”¨å»ºè®®
--------

æ¨èé…ç½®ï¼ˆæœ€ä½³å®è·µï¼‰
~~~~~~~~~~~~~~~~~~~~

.. code-block:: python

    # 1. Training set: find optimal threshold
    train_result = calculate_metrics_at_target(
        y_train_true,
        y_train_prob,
        targets={'sensitivity': 0.91, 'specificity': 0.91, 'ppv': 0.85},
        threshold_selection='pareto+youden',  # Intelligent selection
        fallback_to_closest=True,             # Enable fallback
        distance_metric='euclidean'
    )

    # 2. Extract threshold
    if train_result['best_threshold']:
        threshold = train_result['best_threshold']['threshold']
        logger.info(f"Best threshold found: {threshold}")
    elif train_result['closest_threshold']:
        threshold = train_result['closest_threshold']['threshold']
        logger.warning(f"Using closest threshold: {threshold}")
    else:
        threshold = 0.5  # Default
        logger.error("No suitable threshold found, using default")

    # 3. Test set: apply training threshold
    test_metrics = apply_threshold(y_test_true, y_test_prob, threshold)

æ€§èƒ½å¯¹æ¯”
--------

.. list-table::
   :header-rows: 1
   :widths: 30 20 20 15

   * - åœºæ™¯
     - ä¼˜åŒ–å‰
     - ä¼˜åŒ–å
     - æå‡
   * - è®¡ç®—8ä¸ªåŸºç¡€æŒ‡æ ‡
     - 8æ¬¡CMè®¡ç®—
     - 1æ¬¡CMè®¡ç®—
     - **8x**
   * - Target metrics (sens+spec)
     - è¾ƒå¿«
     - è¾ƒå¿«
     - ~1x
   * - Target metrics (+ppv+npv+f1)
     - N/A
     - ä¸­ç­‰
     - æ–°åŠŸèƒ½
   * - Paretoæœ€ä¼˜é€‰æ‹©
     - N/A
     - ä¸­ç­‰
     - æ–°åŠŸèƒ½

**æ¨è**ï¼š

* æ—¥å¸¸ä½¿ç”¨ï¼šå¯ç”¨ç¼“å­˜
* ç®€å•åœºæ™¯ï¼šåªç”¨sensitivity+specificity
* å¤æ‚åœºæ™¯ï¼šå¯å¢åŠ ppv/npv/f1ï¼ˆæ€§èƒ½æ¢ç²¾åº¦ï¼‰

æµ‹è¯•éªŒè¯
--------

è¿è¡Œæµ‹è¯•å¥—ä»¶ï¼š

.. code-block:: bash

    pytest tests/test_metrics_optimization.py -v

æµ‹è¯•è¦†ç›–ï¼š

* âœ… æ··æ·†çŸ©é˜µç¼“å­˜æ€§èƒ½
* âœ… PPV/NPV/F1ç›®æ ‡æ”¯æŒ
* âœ… Fallbackæœºåˆ¶
* âœ… Pareto+Youdené€‰æ‹©
* âœ… ç±»åˆ«ç­›é€‰
* âœ… ä¸åŒè·ç¦»åº¦é‡

å·²çŸ¥é™åˆ¶
--------

1. **PPV/NPVè®¡ç®—æ…¢**ï¼šéœ€è¦éå†æ‰€æœ‰é˜ˆå€¼ï¼ŒO(n)å¤æ‚åº¦
   
   * å»ºè®®ï¼šä¼˜å…ˆç”¨sensitivity+specificityï¼Œå¿…è¦æ—¶æ‰åŠ ppv/npv

2. **Paretoç®—æ³•å¤æ‚åº¦**ï¼šO(nÂ²) worst case
   
   * å®é™…å½±å“å°ï¼ˆé˜ˆå€¼æ•°é‡é€šå¸¸<1000ï¼‰

3. **å¤šåˆ†ç±»å®Œå…¨æ”¯æŒ**ï¼šéœ€è¦æ›´å¤šæµ‹è¯•å’ŒéªŒè¯
   
   * å½“å‰ï¼šåŸºç¡€æ”¯æŒï¼ˆmacro averageï¼‰
   * æœªæ¥ï¼šweighted, per-classç­‰ç­–ç•¥

æœªæ¥æ”¹è¿›æ–¹å‘
------------

1. **GPUåŠ é€Ÿ**ï¼šæ··æ·†çŸ©é˜µè®¡ç®—ï¼ˆå¤§è§„æ¨¡æ•°æ®ï¼‰
2. **å¹¶è¡ŒåŒ–**ï¼šParetoæœ€ä¼˜æœç´¢ï¼ˆå¤šçº¿ç¨‹ï¼‰
3. **è‡ªé€‚åº”ç­–ç•¥**ï¼šæ ¹æ®æ•°æ®è‡ªåŠ¨é€‰æ‹©threshold_selection
4. **å¯è§†åŒ–**ï¼šParetoå‰æ²¿æ›²çº¿ç»˜åˆ¶
5. **å¤šåˆ†ç±»å…¨é¢æ”¯æŒ**ï¼šweighted, per-classç­–ç•¥

æŠ€æœ¯å€ºåŠ¡æ¸…ç†
------------

å·²è§£å†³çš„æŠ€æœ¯å€ºï¼š

* âœ… é‡å¤è®¡ç®—æ··æ·†çŸ©é˜µï¼ˆ8xæ€§èƒ½æŸå¤±ï¼‰
* âœ… ç¡¬ç¼–ç åªæ”¯æŒsens/spec
* âœ… æ— fallbackæœºåˆ¶
* âœ… categoryå‚æ•°æœªä½¿ç”¨
* âœ… F1-scoreä½æ•ˆè®¡ç®—ï¼ˆ3æ¬¡CMï¼‰

ç¤ºä¾‹ä»£ç 
--------

å®Œæ•´å·¥ä½œæµç¤ºä¾‹
~~~~~~~~~~~~~~

.. code-block:: python

    import numpy as np
    from habit.core.machine_learning.evaluation.metrics import (
        calculate_metrics_at_target,
        calculate_metrics
    )

    # Simulated data
    np.random.seed(42)
    y_train_true = np.random.randint(0, 2, 300)
    y_train_prob = np.random.rand(300)
    y_test_true = np.random.randint(0, 2, 100)
    y_test_prob = np.random.rand(100)

    # Step 1: Find optimal threshold in training set
    train_result = calculate_metrics_at_target(
        y_train_true,
        y_train_prob,
        targets={
            'sensitivity': 0.85,
            'specificity': 0.85,
            'ppv': 0.80
        },
        threshold_selection='pareto+youden',
        fallback_to_closest=True
    )

    # Step 2: Extract and log threshold
    if 'best_threshold' in train_result and train_result['best_threshold']:
        threshold = train_result['best_threshold']['threshold']
        print(f"Best threshold: {threshold}")
        print(f"Strategy: {train_result['best_threshold']['strategy']}")
        print(f"Youden: {train_result['best_threshold']['youden_index']}")
    elif 'closest_threshold' in train_result and train_result['closest_threshold']:
        threshold = train_result['closest_threshold']['threshold']
        print(f"Closest threshold: {threshold}")
        print(f"Distance: {train_result['closest_threshold']['distance_to_target']}")
    else:
        threshold = 0.5
        print("Using default threshold: 0.5")

    # Step 3: Apply to test set
    y_test_pred = (y_test_prob >= threshold).astype(int)
    test_metrics = calculate_metrics(
        y_test_true, 
        y_test_pred, 
        y_test_prob,
        use_cache=True,
        categories=['basic']
    )

    print(f"Test metrics: {test_metrics}")

ç±»åˆ«ç­›é€‰ç¤ºä¾‹
~~~~~~~~~~~~

.. code-block:: python

    from habit.core.machine_learning.evaluation.metrics import calculate_metrics

    # Only basic metrics (fast)
    basic = calculate_metrics(
        y_true, y_pred, y_prob,
        categories=['basic']
    )
    print("Basic metrics:", basic.keys())
    # Output: accuracy, sensitivity, specificity, ppv, npv, f1_score, auc

    # Only statistical metrics
    stats = calculate_metrics(
        y_true, y_pred, y_prob,
        categories=['statistical']
    )
    print("Statistical metrics:", stats.keys())
    # Output: hosmer_lemeshow_p_value, spiegelhalter_z_p_value

    # All metrics
    all_metrics = calculate_metrics(y_true, y_pred, y_prob)
    print("All metrics:", all_metrics.keys())

APIå‚è€ƒ
-------

calculate_metrics_at_target
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: python

    def calculate_metrics_at_target(
        y_true: np.ndarray,
        y_pred_proba: np.ndarray,
        targets: Dict[str, float],
        threshold_selection: str = 'first',
        fallback_to_closest: bool = False,
        distance_metric: str = 'euclidean'
    ) -> Dict[str, Any]

**å‚æ•°**ï¼š

* ``y_true`` (*np.ndarray*): True labels
* ``y_pred_proba`` (*np.ndarray*): Predicted probabilities
* ``targets`` (*Dict[str, float]*): Target metric values
* ``threshold_selection`` (*str*): 'first', 'youden', or 'pareto+youden' (default: 'first')
* ``fallback_to_closest`` (*bool*): Enable fallback mechanism (default: False)
* ``distance_metric`` (*str*): 'euclidean', 'manhattan', or 'max' (default: 'euclidean')

**è¿”å›**ï¼š

Dictionary with keys: ``best_threshold``, ``closest_threshold``, ``combined_results``, ``all_thresholds``

calculate_metrics
~~~~~~~~~~~~~~~~~

.. code-block:: python

    def calculate_metrics(
        y_true: np.ndarray,
        y_pred: np.ndarray,
        y_prob: np.ndarray,
        use_cache: bool = True,
        categories: Optional[List[str]] = None
    ) -> Dict[str, float]

**å‚æ•°**ï¼š

* ``y_true`` (*np.ndarray*): True labels
* ``y_pred`` (*np.ndarray*): Predicted labels
* ``y_prob`` (*np.ndarray*): Predicted probabilities
* ``use_cache`` (*bool*): Enable confusion matrix caching (default: True)
* ``categories`` (*Optional[List[str]]*): List of metric categories to compute (default: None = all)

**è¿”å›**ï¼š

Dictionary of metric name to value

è”ç³»ä¸åé¦ˆ
----------

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·æäº¤Issueæˆ–Pull Requestã€‚

| **ä½œè€…**ï¼šHABITå¼€å‘å›¢é˜Ÿ
| **æ—¥æœŸ**ï¼š2026-01-25
| **ç‰ˆæœ¬**ï¼šv2.0
